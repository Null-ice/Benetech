{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd81208",
   "metadata": {
    "papermill": {
     "duration": 0.009237,
     "end_time": "2023-06-20T04:40:49.334141",
     "exception": false,
     "start_time": "2023-06-20T04:40:49.324904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Benetech: <span style='color:#F1A424'>Pix2Struct</span><span style='color:#ABABAB'> [Inference]</span></b> \n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "### <b><span style='color:#F1A424'>Table of Contents</span></b> <a class='anchor' id='top'></a>\n",
    "<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n",
    "<li> <a href=\"#introduction\">Introduction</a></li>\n",
    "<li> <a href=\"#install_libraries\">Install libraries</a></li>\n",
    "<li><a href=\"#import_libraries\">Import Libraries</a></li>\n",
    "<li><a href=\"#configuration\">Configuration</a></li>\n",
    "<li><a href=\"#utils\">Utils</a></li>\n",
    "<li><a href=\"#pre_processing\">Load Data</a></li>\n",
    "<li><a href=\"#model\">Model</a></li>\n",
    "<li><a href=\"#dataset\">Dataset</a></li>\n",
    "<li><a href=\"#collate\">Collate Function</a></li>\n",
    "<li><a href=\"#dataloader\">DataLoader</a></li>\n",
    "<li><a href=\"#inference\">Inference</a></li>\n",
    "<li><a href=\"#submission\">Submission</a></li>\n",
    "<li><a href=\"#q_and_a\">Quality Assurance</a></li>\n",
    "</div>\n",
    "\n",
    "\n",
    "# <b><span style='color:#F1A424'>|</span> Introduction</b><a class='anchor' id='introduction'></a> [↑](#top) \n",
    "\n",
    "***\n",
    "\n",
    "### <b><span style='color:#F1A424'>Useful References</span></b>\n",
    "\n",
    "- [Pix2Struct HuggingFace Demo](https://github.com/huggingface/notebooks/blob/main/examples/image_captioning_pix2struct.ipynb)\n",
    "- [Issues in training discussion](https://github.com/huggingface/transformers/issues/22903)\n",
    "- [Pix2Struct Niels Rogge Demo](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Pix2Struct/Fine_tune_Pix2Struct_on_key_value_pair_dataset_(PyTorch_Lightning).ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0ddc8",
   "metadata": {
    "papermill": {
     "duration": 0.006711,
     "end_time": "2023-06-20T04:40:49.347686",
     "exception": false,
     "start_time": "2023-06-20T04:40:49.340975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Install Libraries</b><a class='anchor' id='install_libraries'></a> [↑](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Check the issue mentioned in the *Useful References*. We need a `transformers` version which has the error fixed. In the future, the latest environments will include the fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f7b29e",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-20T04:40:49.363662Z",
     "iopub.status.busy": "2023-06-20T04:40:49.362834Z",
     "iopub.status.idle": "2023-06-20T04:41:30.353401Z",
     "shell.execute_reply": "2023-06-20T04:41:30.352251Z"
    },
    "papermill": {
     "duration": 41.001434,
     "end_time": "2023-06-20T04:41:30.356053",
     "exception": false,
     "start_time": "2023-06-20T04:40:49.354619",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.28.1\r\n",
      "Uninstalling transformers-4.28.1:\r\n",
      "  Successfully uninstalled transformers-4.28.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: /kaggle/input/benetech-pip\r\n",
      "Processing /kaggle/input/benetech-pip/transformers-4.30.0.dev0.zip\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\r\n",
      "Processing /kaggle/input/benetech-pip/huggingface_hub-0.14.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.30.0.dev0-py3-none-any.whl size=7120338 sha256=cd73a6fa626a1484d585f373693f5fbd010e5b1e27cdf34a44bc12bec1aded3e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/06/f4/a315c5665163a83bde1d7b42bfc743ecf2a684baa63f39161b\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: huggingface-hub, transformers\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.13.4\r\n",
      "    Uninstalling huggingface-hub-0.13.4:\r\n",
      "      Successfully uninstalled huggingface-hub-0.13.4\r\n",
      "Successfully installed huggingface-hub-0.14.1 transformers-4.30.0.dev0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers -y\n",
    "!python -m pip install --no-index --find-links=/kaggle/input/benetech-pip transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34280005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:30.378976Z",
     "iopub.status.busy": "2023-06-20T04:41:30.378633Z",
     "iopub.status.idle": "2023-06-20T04:41:32.168007Z",
     "shell.execute_reply": "2023-06-20T04:41:32.166906Z"
    },
    "papermill": {
     "duration": 1.803349,
     "end_time": "2023-06-20T04:41:32.170109",
     "exception": false,
     "start_time": "2023-06-20T04:41:30.366760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets version: 2.1.0\n",
      "transformers version: 4.30.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "\n",
    "print(f\"datasets version: {datasets.__version__}\") # should be 2.12.0 \n",
    "print(f\"transformers version: {transformers.__version__}\") # should be 4.29.0.dev0 or higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1b75c",
   "metadata": {
    "papermill": {
     "duration": 0.01045,
     "end_time": "2023-06-20T04:41:32.191136",
     "exception": false,
     "start_time": "2023-06-20T04:41:32.180686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Import Libraries</b><a class='anchor' id='import_libraries'></a> [↑](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Import all the required libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e011c7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:32.213260Z",
     "iopub.status.busy": "2023-06-20T04:41:32.212698Z",
     "iopub.status.idle": "2023-06-20T04:41:43.613037Z",
     "shell.execute_reply": "2023-06-20T04:41:43.612016Z"
    },
    "papermill": {
     "duration": 11.41412,
     "end_time": "2023-06-20T04:41:43.615540",
     "exception": false,
     "start_time": "2023-06-20T04:41:32.201420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from datasets import Dataset as HFDataset, DatasetDict\n",
    "from datasets import Image as ds_img\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from nltk import edit_distance\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import Pix2StructForConditionalGeneration, AutoProcessor\n",
    "from typing import List, Dict, Union, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343b7d5",
   "metadata": {
    "papermill": {
     "duration": 0.010505,
     "end_time": "2023-06-20T04:41:43.636803",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.626298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [↑](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Central repository for this notebook's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f00a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:43.659752Z",
     "iopub.status.busy": "2023-06-20T04:41:43.658851Z",
     "iopub.status.idle": "2023-06-20T04:41:43.720954Z",
     "shell.execute_reply": "2023-06-20T04:41:43.720061Z"
    },
    "papermill": {
     "duration": 0.076108,
     "end_time": "2023-06-20T04:41:43.723375",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.647267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    BATCH_SIZE = 4\n",
    "    DEBUG = False\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    GPUS = 2\n",
    "    NUM_PROCESS = 2\n",
    "    NUM_WORKERS = multiprocessing.cpu_count()\n",
    "    VERBOSE = True\n",
    "\n",
    "    \n",
    "class paths:\n",
    "    BEST_MODEL = \"/kaggle/input/matcha-amp\"\n",
    "    TEST_FOLDER = \"/kaggle/input/benetech-making-graphs-accessible/train\"\n",
    "    TEST_IMAGES_FOLDER = \"/kaggle/input/benetech-making-graphs-accessible/test/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d03073",
   "metadata": {
    "papermill": {
     "duration": 0.010434,
     "end_time": "2023-06-20T04:41:43.744373",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.733939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top) \n",
    "\n",
    "***\n",
    "\n",
    "Utility functions used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee90120e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:43.766865Z",
     "iopub.status.busy": "2023-06-20T04:41:43.766521Z",
     "iopub.status.idle": "2023-06-20T04:41:43.778850Z",
     "shell.execute_reply": "2023-06-20T04:41:43.777910Z"
    },
    "papermill": {
     "duration": 0.025969,
     "end_time": "2023-06-20T04:41:43.780811",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.754842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_START = \"<s_x_values>\"\n",
    "X_END = \"</s_x_values>\"\n",
    "Y_START = \"<s_y_values>\"\n",
    "Y_END = \"</s_y_values>\"\n",
    "CHART_START = \"<s_chart>\"\n",
    "CHART_END = \"</s_chart>\"\n",
    "\n",
    "\n",
    "def get_text(text: str, start_token: str, end_token: str, exception: str):\n",
    "    \"\"\"\n",
    "    This functions retrieves text data between two tokens. If the tokens are not present it defaults to\n",
    "    an exception string.\n",
    "    \"\"\"\n",
    "    pattern = f\"{start_token}(.*?){end_token}\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    if matches:\n",
    "        data = matches[0]\n",
    "    else:\n",
    "        data = exception\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_prediction(preds: List[Dict]):\n",
    "    \"\"\"\n",
    "    This function extracts the relevant information from the model's predictions. Predictions are\n",
    "    lists of strings, where the relevant data is enclosed by special tokens.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for pred in preds:\n",
    "        pred_dictionary = {}\n",
    "        prediction = pred[\"prediction\"]\n",
    "        pred_dictionary[\"id\"] = pred[\"id\"]\n",
    "        pred_dictionary[\"chart_type\"] = get_text(text=prediction, start_token=CHART_START,\n",
    "                                                 end_token=CHART_END, exception=\"line\")\n",
    "        pred_dictionary[\"data_series_x\"] = get_text(text=prediction, start_token=X_START,\n",
    "                                                  end_token=X_END, exception=\"0;0\")\n",
    "        pred_dictionary[\"data_series_y\"] = get_text(text=prediction, start_token=Y_START,\n",
    "                                                  end_token=Y_END, exception=\"0;0\")\n",
    "        output.append(pred_dictionary)\n",
    "    return output\n",
    "\n",
    "\n",
    "def format_submission(preds: List[Dict]):\n",
    "    \"\"\"\n",
    "    Since we need to have one prediction per axis we need to format our predictions.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for prediction in predictions:\n",
    "        prediction_x, prediction_y = {}, {}\n",
    "        prediction_x[\"id\"] = prediction[\"id\"] + \"_x\"\n",
    "        prediction_y[\"id\"] = prediction[\"id\"] + \"_y\"\n",
    "        prediction_x[\"data_series\"] = prediction[\"data_series_x\"]\n",
    "        prediction_y[\"data_series\"] = prediction[\"data_series_y\"]\n",
    "        prediction_x[\"chart_type\"] = prediction[\"chart_type\"]\n",
    "        prediction_y[\"chart_type\"] = prediction[\"chart_type\"]\n",
    "        output.append(prediction_x)\n",
    "        output.append(prediction_y)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089b7f9",
   "metadata": {
    "papermill": {
     "duration": 0.010345,
     "end_time": "2023-06-20T04:41:43.801518",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.791173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [↑](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ddd1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:43.823521Z",
     "iopub.status.busy": "2023-06-20T04:41:43.823188Z",
     "iopub.status.idle": "2023-06-20T04:41:43.880925Z",
     "shell.execute_reply": "2023-06-20T04:41:43.880033Z"
    },
    "papermill": {
     "duration": 0.071088,
     "end_time": "2023-06-20T04:41:43.882944",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.811856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = Path(paths.TEST_IMAGES_FOLDER)\n",
    "images = list(image_dir.glob(\"*.jpg\"))\n",
    "\n",
    "ds = HFDataset.from_dict({\n",
    "    \"image_path\": [str(x) for x in images],\n",
    "    \"id\": [x.stem for x in images]\n",
    "}).cast_column(\"image_path\", ds_img())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ee944",
   "metadata": {
    "papermill": {
     "duration": 0.010202,
     "end_time": "2023-06-20T04:41:43.903827",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.893625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [↑](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82dbab97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:43.926722Z",
     "iopub.status.busy": "2023-06-20T04:41:43.925828Z",
     "iopub.status.idle": "2023-06-20T04:41:57.228626Z",
     "shell.execute_reply": "2023-06-20T04:41:57.227490Z"
    },
    "papermill": {
     "duration": 13.316929,
     "end_time": "2023-06-20T04:41:57.231155",
     "exception": false,
     "start_time": "2023-06-20T04:41:43.914226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(paths.BEST_MODEL, is_vqa=False)\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained(paths.BEST_MODEL, is_vqa=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cbe3d",
   "metadata": {
    "papermill": {
     "duration": 0.010438,
     "end_time": "2023-06-20T04:41:57.252594",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.242156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Dataset</b><a class='anchor' id='dataset'></a> [↑](#top) \n",
    "\n",
    "***\n",
    "\n",
    "We will create a `CustomDataset` class. It's very similar to the standard PyTorch `Dataset` class with the required `__init__()`, `__len__()` and `__getitem__()` methods plus an additional `add_tokens()` method which adds custom tokens to the model's tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee35676f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:57.274861Z",
     "iopub.status.busy": "2023-06-20T04:41:57.274535Z",
     "iopub.status.idle": "2023-06-20T04:41:57.283109Z",
     "shell.execute_reply": "2023-06-20T04:41:57.282208Z"
    },
    "papermill": {
     "duration": 0.022014,
     "end_time": "2023-06-20T04:41:57.285033",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.263019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: DatasetDict,\n",
    "        max_patches: int = 512,\n",
    "        max_length: int = 512,\n",
    "        new_tokens: list = []\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initialize CustomDataset instance.\n",
    "        :param dataset (DatasetDict): HuggingFace DatasetDict instance\n",
    "        :param max_patches (int): Maximum number of patches to extract\n",
    "        :param max_length (int):     \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.max_patches = max_patches\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        item = self.dataset[idx]\n",
    "        encoding = processor(\n",
    "            images=item[\"image_path\"],\n",
    "            max_patches=self.max_patches,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "        encoding[\"id\"] = item[\"id\"]\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048227cc",
   "metadata": {
    "papermill": {
     "duration": 0.01038,
     "end_time": "2023-06-20T04:41:57.305826",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.295446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <b><span style='color:#F1A424'>Create inference dataset</span></b>\n",
    "\n",
    "The [preprocess](https://github.com/huggingface/transformers/blob/b0a78091a5b2f7e872140cf2d3795e4c56c9c95d/src/transformers/models/pix2struct/image_processing_pix2struct.py#L323) encoding consists of three parts:\n",
    "- `flattened_patches`: image patches.\n",
    "- `attention_mask`: attention mask. Tensor with 1s and 0s.\n",
    "- `id`: id of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fad2ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:57.327745Z",
     "iopub.status.busy": "2023-06-20T04:41:57.327451Z",
     "iopub.status.idle": "2023-06-20T04:41:57.419558Z",
     "shell.execute_reply": "2023-06-20T04:41:57.418272Z"
    },
    "papermill": {
     "duration": 0.105454,
     "end_time": "2023-06-20T04:41:57.421638",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.316184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding keys: dict_keys(['flattened_patches', 'attention_mask', 'id']) \n",
      "\n",
      "Unique tokens in tokenizer: 50350 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inference_dataset = CustomDataset(dataset=ds)\n",
    "\n",
    "# === Let's check one sample ===\n",
    "encoding = inference_dataset[0]\n",
    "# decoded_text = processor.decode(encoding[\"labels\"]) # uncomment to show <pad>\n",
    "print(f\"Encoding keys: {encoding.keys()} \\n\") \n",
    "print(f\"Unique tokens in tokenizer: {len(processor.tokenizer)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1b105",
   "metadata": {
    "papermill": {
     "duration": 0.010426,
     "end_time": "2023-06-20T04:41:57.442719",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.432293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Collate Function</b><a class='anchor' id='collate'></a> [↑](#top) \n",
    "\n",
    "***\n",
    "\n",
    "The `collate` function in Hugging Face refers to the process of combining and organizing a batch of individual examples into a single batch tensor or data structure. It is commonly used in natural language processing (NLP) tasks such as text classification or language modeling.\n",
    "\n",
    "Hugging Face provides a `DataCollator` class that implements the `collate` function. It takes care of tasks like padding sequences to a common length, creating attention masks, and handling any additional processing specific to the task or model being used.\n",
    "\n",
    "By using the `collate` function, you can efficiently preprocess and prepare your data for training or inference with Hugging Face's models and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5668363a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:57.466359Z",
     "iopub.status.busy": "2023-06-20T04:41:57.464787Z",
     "iopub.status.idle": "2023-06-20T04:41:57.472562Z",
     "shell.execute_reply": "2023-06-20T04:41:57.471700Z"
    },
    "papermill": {
     "duration": 0.021207,
     "end_time": "2023-06-20T04:41:57.474504",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.453297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collator(batch):\n",
    "    new_batch = {\"flattened_patches\":[], \"attention_mask\":[], \"id\":[]}\n",
    "    \n",
    "    for item in batch:\n",
    "        new_batch[\"flattened_patches\"].append(item[\"flattened_patches\"])\n",
    "        new_batch[\"attention_mask\"].append(item[\"attention_mask\"])\n",
    "        new_batch[\"id\"].append(item[\"id\"])\n",
    "\n",
    "    new_batch[\"flattened_patches\"] = torch.stack(new_batch[\"flattened_patches\"])\n",
    "    new_batch[\"attention_mask\"] = torch.stack(new_batch[\"attention_mask\"])\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96fdf02",
   "metadata": {
    "papermill": {
     "duration": 0.010254,
     "end_time": "2023-06-20T04:41:57.495200",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.484946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> DataLoader</b><a class='anchor' id='dataloader'></a> [↑](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676402d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:57.518520Z",
     "iopub.status.busy": "2023-06-20T04:41:57.516984Z",
     "iopub.status.idle": "2023-06-20T04:41:57.790876Z",
     "shell.execute_reply": "2023-06-20T04:41:57.789750Z"
    },
    "papermill": {
     "duration": 0.287952,
     "end_time": "2023-06-20T04:41:57.793472",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.505520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flattened_patches shape: torch.Size([4, 512, 770]) \n",
      "\n",
      "attention_mask shape: torch.Size([4, 512]) \n",
      "\n",
      "id shape: 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inference_dataloader = DataLoader(inference_dataset, batch_size=config.BATCH_SIZE,\n",
    "                                  shuffle=False, num_workers=config.NUM_WORKERS, collate_fn=collator)\n",
    "\n",
    "# === Let's check one sample ===\n",
    "batch = next(iter(inference_dataloader))\n",
    "encoding = batch\n",
    "\n",
    "# === Iterate over each element in the dictionary and print shape ===\n",
    "for k,v in encoding.items():\n",
    "    try:\n",
    "        print(f\"{k} shape: {v.shape} \\n\")\n",
    "    except:\n",
    "        print(f\"{k} shape: {len(v)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5846a58e",
   "metadata": {
    "papermill": {
     "duration": 0.010372,
     "end_time": "2023-06-20T04:41:57.814827",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.804455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Inference</b><a class='anchor' id='inference'></a> [↑](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb93636b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:41:57.838384Z",
     "iopub.status.busy": "2023-06-20T04:41:57.837701Z",
     "iopub.status.idle": "2023-06-20T04:42:49.240173Z",
     "shell.execute_reply": "2023-06-20T04:42:49.238980Z"
    },
    "papermill": {
     "duration": 51.417649,
     "end_time": "2023-06-20T04:42:49.243198",
     "exception": false,
     "start_time": "2023-06-20T04:41:57.825549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:43<00:43, 43.81s/test_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | Prediction: [{'id': '000b92c3b098', 'prediction': '<s_chart> line</s_chart><s_x_values> 0;6;12;18;24</s_x_values><s_y_values> 0.0000;-1.3232;-1.2132;-1.9432;-1.2432</s_y_values>'}, {'id': '01b45b831589', 'prediction': '<s_chart> vertical_bar</s_chart><s_x_values> 21-Feb ; 21-Mar ; 23-Apr ; 23-May ; 24-Jun ; 22-Jul ; 26-Aug ; 27-Sep ; 27-Oct ; 2-Nov ; 2-Dec ; 0-Dec ; 0-Nov ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Nov ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Nov ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Dec ; 0-Dec ; 0-'}, {'id': '00f5404753cf', 'prediction': '<s_chart> scatter</s_chart><s_x_values> 0.6 ; 0.6 ; 0.6 ; 0.7 ; 0.8 ; 0.8 ; 0.9 ; 1.0 ; 1.0 ; 1.1 ; 1.2 ; 1.2 ; 1.3 ; 1.4 ; 1.4 ; 1.5 ; 1.6 ; 1.6 ; 1.7 ; 1.7 ; 1.8 ; 1.8 ; 1.8 ; 1.9 ; 2.0 ; 2.0 ; 2.0 ; 2.1 ; 2.2 ; 2.2 ; 2.3 ; 2.4 ; 2.4 ; 2.5 ; 2.6 ; 2.6 ; 2.7 ; 2.7 ; 2.8 ; 2.8 ; 2.9 ; 3.0 ; 3.0 ; 3.1 ; 3.2 ; 3.3 ; 3.4 ; 3.5 ; 3.5 ; 3.6 ; 3.7 ; 3.7 ; 3.8 ; 3.8 ; 3.9 ; 4.0 ; 4.0 ; 4.1 ; 4.2 ; 4.3 ; 4.4 ; 4.5 ; 4.6 ; 4.6 ; 4.7 ; 4.8 ; 4.8 ; 5.0 ; 5.0 ; 5.1 ; 5.2 ; 5.3 ; 5.4 ; 5.5 ; 5.6 ; 5.7 ; 5.8 ; 5.9 ; 6.0 ; 6.0 ; 6.1 ; 6.3 ; 6.3 ; 6.4 ; 6.5'}, {'id': '00dcf883a459', 'prediction': '<s_chart> vertical_bar</s_chart><s_x_values> Group 1;Group 2</s_x_values><s_y_values> 3.5;8.3</s_y_values>'}]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:46<00:00, 23.21s/test_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 | Prediction: [{'id': '007a18eb4e09', 'prediction': '<s_chart> line</s_chart><s_x_values> 0;0.4;0.8;1.2;1.6;2.0;2.4;2.8</s_x_values><s_y_values> 0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.0132</s_y_values>'}]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = config.DEVICE\n",
    "model.to(device)\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(inference_dataloader, unit=\"test_batch\")):\n",
    "        ids = batch.pop(\"id\")\n",
    "        flattened_patches = batch.pop(\"flattened_patches\").to(device)\n",
    "        attention_mask = batch.pop(\"attention_mask\").to(device)\n",
    "        prediction = model.generate(\n",
    "            flattened_patches=flattened_patches,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=512,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "        preds = processor.batch_decode(prediction, skip_special_tokens=True)\n",
    "        preds = [{'id': id_value, 'prediction': pred_value} for id_value, pred_value in zip(ids, preds)]\n",
    "        predictions += get_prediction(preds)\n",
    "        print(f'Step: {step} | Prediction: {preds}'), print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfbc357",
   "metadata": {
    "papermill": {
     "duration": 0.010794,
     "end_time": "2023-06-20T04:42:49.265551",
     "exception": false,
     "start_time": "2023-06-20T04:42:49.254757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Submission</b><a class='anchor' id='submission'></a> [↑](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c359e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:42:49.289475Z",
     "iopub.status.busy": "2023-06-20T04:42:49.288530Z",
     "iopub.status.idle": "2023-06-20T04:42:49.317015Z",
     "shell.execute_reply": "2023-06-20T04:42:49.316080Z"
    },
    "papermill": {
     "duration": 0.042599,
     "end_time": "2023-06-20T04:42:49.319092",
     "exception": false,
     "start_time": "2023-06-20T04:42:49.276493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data_series</th>\n",
       "      <th>chart_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000b92c3b098_x</td>\n",
       "      <td>0;6;12;18;24</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000b92c3b098_y</td>\n",
       "      <td>0.0000;-1.3232;-1.2132;-1.9432;-1.2432</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01b45b831589_x</td>\n",
       "      <td>0;0</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01b45b831589_y</td>\n",
       "      <td>0;0</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00f5404753cf_x</td>\n",
       "      <td>0;0</td>\n",
       "      <td>scatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00f5404753cf_y</td>\n",
       "      <td>0;0</td>\n",
       "      <td>scatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00dcf883a459_x</td>\n",
       "      <td>Group 1;Group 2</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00dcf883a459_y</td>\n",
       "      <td>3.5;8.3</td>\n",
       "      <td>vertical_bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007a18eb4e09_x</td>\n",
       "      <td>0;0.4;0.8;1.2;1.6;2.0;2.4;2.8</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>007a18eb4e09_y</td>\n",
       "      <td>0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.0...</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                        data_series  \\\n",
       "0  000b92c3b098_x                                       0;6;12;18;24   \n",
       "1  000b92c3b098_y             0.0000;-1.3232;-1.2132;-1.9432;-1.2432   \n",
       "2  01b45b831589_x                                                0;0   \n",
       "3  01b45b831589_y                                                0;0   \n",
       "4  00f5404753cf_x                                                0;0   \n",
       "5  00f5404753cf_y                                                0;0   \n",
       "6  00dcf883a459_x                                    Group 1;Group 2   \n",
       "7  00dcf883a459_y                                            3.5;8.3   \n",
       "8  007a18eb4e09_x                      0;0.4;0.8;1.2;1.6;2.0;2.4;2.8   \n",
       "9  007a18eb4e09_y   0.0132;0.0132;0.0132;0.0132;0.0132;0.0132;0.0...   \n",
       "\n",
       "     chart_type  \n",
       "0          line  \n",
       "1          line  \n",
       "2  vertical_bar  \n",
       "3  vertical_bar  \n",
       "4       scatter  \n",
       "5       scatter  \n",
       "6  vertical_bar  \n",
       "7  vertical_bar  \n",
       "8          line  \n",
       "9          line  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(format_submission(predictions))\n",
    "submission[\"chart_type\"] = submission[\"chart_type\"].apply(lambda x: re.sub(r\"\\s\", \"\", x))\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ce825",
   "metadata": {
    "papermill": {
     "duration": 0.011107,
     "end_time": "2023-06-20T04:42:49.341502",
     "exception": false,
     "start_time": "2023-06-20T04:42:49.330395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <b><span style='color:#F1A424'>|</span> Quality Assurance</b><a class='anchor' id='q_and_a'></a> [↑](#top) \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b8f94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T04:42:49.366080Z",
     "iopub.status.busy": "2023-06-20T04:42:49.365746Z",
     "iopub.status.idle": "2023-06-20T04:42:49.377014Z",
     "shell.execute_reply": "2023-06-20T04:42:49.376130Z"
    },
    "papermill": {
     "duration": 0.026085,
     "end_time": "2023-06-20T04:42:49.378912",
     "exception": false,
     "start_time": "2023-06-20T04:42:49.352827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    assert len(submission) == len(glob(paths.TEST_IMAGES_FOLDER + \"/*.jpg\"))*2\n",
    "except:\n",
    "    raise ValueError(\"The number of rows in submission/2 does not match the number of images.\")\n",
    "    \n",
    "try:\n",
    "    assert submission.id.nunique() == len(glob(paths.TEST_IMAGES_FOLDER + \"/*.jpg\"))*2\n",
    "except:\n",
    "    raise ValueError(\"The number of unique IDs/2 does not match the number of images.\")\n",
    "    \n",
    "try:\n",
    "    assert submission.columns.tolist() == ['id', 'data_series', 'chart_type']\n",
    "except:\n",
    "    raise ValueError(\"Wrong column names.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 134.859524,
   "end_time": "2023-06-20T04:42:52.862728",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-20T04:40:38.003204",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
